"""éªŒè¯æ¨¡å‹é…ç½®è„šæœ¬

ç”¨äºæ£€æŸ¥ config.yaml å’Œ agents.yaml é…ç½®æ˜¯å¦æ­£ç¡®
ä»¥åŠæœ¬åœ° Ollama æ¨¡å‹æ˜¯å¦å¯ç”¨
"""

import yaml
import requests
import sys
from pathlib import Path


def load_config(config_path: str):
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    except Exception as e:
        print(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥ {config_path}: {e}")
        return None


def check_ollama_service(base_url: str):
    """æ£€æŸ¥ Ollama æœåŠ¡æ˜¯å¦è¿è¡Œ"""
    try:
        response = requests.get(f"{base_url}/api/tags", timeout=5)
        if response.status_code == 200:
            return True, response.json()
        else:
            return False, None
    except Exception as e:
        return False, str(e)


def verify_model_availability(models_data, required_models):
    """éªŒè¯æ‰€éœ€æ¨¡å‹æ˜¯å¦å·²å®‰è£…"""
    if not models_data:
        return []
    
    installed_models = []
    if 'models' in models_data:
        for model in models_data['models']:
            installed_models.append(model['name'])
    
    results = []
    for model_name in required_models:
        # æ£€æŸ¥å®Œæ•´åŒ¹é…æˆ–éƒ¨åˆ†åŒ¹é…ï¼ˆå¤„ç†ç‰ˆæœ¬å·ï¼‰
        found = False
        for installed in installed_models:
            if model_name in installed or installed.startswith(model_name.split(':')[0]):
                found = True
                break
        results.append((model_name, found))
    
    return results


def main():
    """ä¸»éªŒè¯æµç¨‹"""
    print("=" * 60)
    print("æ¨¡å‹é…ç½®éªŒè¯å·¥å…·")
    print("=" * 60)
    print()
    
    # 1. æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    print("ğŸ“‹ æ­¥éª¤ 1: æ£€æŸ¥é…ç½®æ–‡ä»¶")
    config_path = Path("config/config.yaml")
    agents_path = Path("config/agents.yaml")
    
    if not config_path.exists():
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return False
    else:
        print(f"âœ… ä¸»é…ç½®æ–‡ä»¶å­˜åœ¨: {config_path}")
    
    if not agents_path.exists():
        print(f"âŒ æ™ºèƒ½ä½“é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {agents_path}")
        return False
    else:
        print(f"âœ… æ™ºèƒ½ä½“é…ç½®æ–‡ä»¶å­˜åœ¨: {agents_path}")
    
    print()
    
    # 2. åŠ è½½å¹¶è§£æé…ç½®
    print("ğŸ“‹ æ­¥éª¤ 2: è§£æé…ç½®æ–‡ä»¶")
    config = load_config(str(config_path))
    agents_config = load_config(str(agents_path))
    
    if not config:
        print("âŒ ä¸»é…ç½®æ–‡ä»¶è§£æå¤±è´¥")
        return False
    else:
        print("âœ… ä¸»é…ç½®æ–‡ä»¶è§£ææˆåŠŸ")
    
    if not agents_config:
        print("âŒ æ™ºèƒ½ä½“é…ç½®æ–‡ä»¶è§£æå¤±è´¥")
        return False
    else:
        print("âœ… æ™ºèƒ½ä½“é…ç½®æ–‡ä»¶è§£ææˆåŠŸ")
    
    print()
    
    # 3. æå–é…ç½®ä¿¡æ¯
    print("ğŸ“‹ æ­¥éª¤ 3: è¯»å–æ¨¡å‹é…ç½®")
    ollama_config = config.get('ollama', {})
    base_url = ollama_config.get('base_url', 'http://localhost:11434')
    default_model = ollama_config.get('default_model', 'llama3:8b')
    embedding_model = ollama_config.get('embedding_model', 'nomic-embed-text:latest')
    
    print(f"   Ollama åœ°å€: {base_url}")
    print(f"   é»˜è®¤æ¨¡å‹: {default_model}")
    print(f"   åµŒå…¥æ¨¡å‹: {embedding_model}")
    print()
    
    # 4. æ”¶é›†æ‰€æœ‰éœ€è¦çš„æ¨¡å‹
    required_models = set()
    required_models.add(default_model)
    required_models.add(embedding_model)
    
    # ä» model_strategy ä¸­æ”¶é›†
    model_strategy = config.get('model_strategy', {})
    for task_type, strategy in model_strategy.items():
        if 'model' in strategy:
            required_models.add(strategy['model'])
    
    # ä» agents ä¸­æ”¶é›†
    agents = agents_config.get('agents', {})
    for agent_name, agent_config in agents.items():
        if 'model_name' in agent_config:
            required_models.add(agent_config['model_name'])
    
    print(f"ğŸ“‹ æ­¥éª¤ 4: éœ€è¦çš„æ¨¡å‹æ¸…å• (å…± {len(required_models)} ä¸ª)")
    for model in sorted(required_models):
        print(f"   - {model}")
    print()
    
    # 5. æ£€æŸ¥ Ollama æœåŠ¡
    print("ğŸ“‹ æ­¥éª¤ 5: æ£€æŸ¥ Ollama æœåŠ¡")
    service_running, models_data = check_ollama_service(base_url)
    
    if not service_running:
        print(f"âŒ Ollama æœåŠ¡æœªè¿è¡Œ: {models_data}")
        print(f"   è¯·ç¡®ä¿ Ollama æœåŠ¡å·²å¯åŠ¨: {base_url}")
        return False
    else:
        print(f"âœ… Ollama æœåŠ¡è¿è¡Œæ­£å¸¸")
    
    print()
    
    # 6. éªŒè¯æ¨¡å‹å¯ç”¨æ€§
    print("ğŸ“‹ æ­¥éª¤ 6: éªŒè¯æ¨¡å‹å®‰è£…çŠ¶æ€")
    model_results = verify_model_availability(models_data, required_models)
    
    all_available = True
    for model_name, available in model_results:
        if available:
            print(f"   âœ… {model_name}")
        else:
            print(f"   âŒ {model_name} - æœªå®‰è£…")
            all_available = False
    
    print()
    
    # 7. æ˜¾ç¤ºæ™ºèƒ½ä½“é…ç½®æ‘˜è¦
    print("ğŸ“‹ æ­¥éª¤ 7: æ™ºèƒ½ä½“é…ç½®æ‘˜è¦")
    for agent_name, agent_config in agents.items():
        model = agent_config.get('model_name', 'N/A')
        temp = agent_config.get('temperature', 'N/A')
        desc = agent_config.get('description', 'N/A')
        print(f"   {agent_name}:")
        print(f"      æ¨¡å‹: {model}")
        print(f"      æ¸©åº¦: {temp}")
        print(f"      æè¿°: {desc}")
    
    print()
    print("=" * 60)
    
    # 8. æœ€ç»ˆç»“æœ
    if all_available:
        print("âœ… é…ç½®éªŒè¯é€šè¿‡ï¼æ‰€æœ‰æ¨¡å‹å‡å¯ç”¨")
        print("   å¯ä»¥è¿è¡Œ: python demo.py")
        print("   æˆ–å¯åŠ¨ç³»ç»Ÿ: python src/cli/main.py")
        return True
    else:
        print("âš ï¸  é…ç½®éªŒè¯éƒ¨åˆ†é€šè¿‡ï¼Œä½†æœ‰æ¨¡å‹ç¼ºå¤±")
        print("   è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ç¼ºå¤±çš„æ¨¡å‹ï¼š")
        for model_name, available in model_results:
            if not available:
                print(f"   ollama pull {model_name}")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
